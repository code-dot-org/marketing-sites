import {eTag} from '@tinyhttp/etag';

import {STALE_WHILE_REVALIDATE_ONE_DAY} from '@/cache/constants';
import {getBrandFromHostname} from '@/config/brand';
import {isAllowedProductionCanonicalHostname} from '@/config/host';
import {getStage} from '@/config/stage';

// Ensure robots.txt is not static generated by the Next.js build
export const dynamic = 'force-dynamic';

const DISALLOW_ALL_RULE = `User-Agent: *
Disallow: /`;

/**
 * GET /robots.txt
 * Returns a robots.txt file that disallows all crawling in non-production environments
 */
export async function GET(request: Request) {
  const host = request.headers.get('host');
  const brand = getBrandFromHostname(host);
  const stage = getStage();

  if (
    stage !== 'production' ||
    !isAllowedProductionCanonicalHostname(brand, host)
  ) {
    return new Response(DISALLOW_ALL_RULE, {
      status: 200,
      headers: {
        'Content-Type': 'text/plain',
        'Cache-Control': STALE_WHILE_REVALIDATE_ONE_DAY,
        ETag: eTag(DISALLOW_ALL_RULE),
      },
    });
  }

  return new Response('', {
    status: 200,
    headers: {
      'Content-Type': 'text/plain',
      'Cache-Control': STALE_WHILE_REVALIDATE_ONE_DAY,
      ETag: eTag(''),
    },
  });
}
